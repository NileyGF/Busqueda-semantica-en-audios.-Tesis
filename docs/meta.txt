Los sistemas de recuperación de música suelen utilizar pocos criterios de clasificación y usualmente a partir de metadatos. 
Esto limita el tipo de búsquedas que se pueden realizar en ellos. Nuestra propuesta es construir un modelo de recuperación 
de información que explote la mayor cantidad de información posible de una base de datos de música determinada; permitiendo 
realizar búsquedas con mayor significación semántica. Dicho modelo estará compuesto, a su vez, por diversos modelos que 
caractericen las canciones por uno o más criterios como pueden ser: el género, idioma, cantidad de cantantes, tema de la canción, 
etc. El modelo de recuperación debe ser capaz de dado una consulta, comprobar que sea una pregunta válida del dominio y 
en ese caso entender que características se desean, y buscar canciones que coincidan con ellas.


Con el desarrollo acelerado de algoritmos de machine learning en los últimos 10 años, 
muchos entornos han cambiado parcial o totalmente su forma de hacer las cosaas para incorporar
esta vertiente de la inteligencia artificial que cada vez es más efectiva respecto a su costo. 
% << insertar ejemplos >>

Sin embargo, en Music Retrieval, la incorporación ha sido bastante lenta. Esto podría confindir 
a lectores que han trabajado o leído sobre los muchos trabajos en clasificacion y reconocimiento de musica.


First lets introduce the information retrieval problem and \\
    mention that most works in music retrieval are content-based  \\
    (given a track find similar musics based on spectograms or the like). \\
    MIR field is focused on Audio Recognition and classification (cite the surveys on MIR) \\
    Mention the lack of query by text music retrieval, highlight the 2-3 examples I've gathered. \\
    Mention the "similarity" between music retrieval and audio retrieval \\
    and how to transfer ideas from that field. \\
    Dig on the dataset problems on music retrieval (even by tags). (copyright) \\
    Speak about audio and music captioning and my dataset alternative \\
    (argument why is better than a autotagging dataset). \\
    Now, explain that usually the criterias for retrieval are too fixated.  \\
    So propose the multi-model idea. Then speak about table to text using transformers. \\
    Then get the embeddings of the generated text for each song. \\
    for the similarity compare the query embedding with every song's. \\
    It implies semantic information due to the embeddings...  \\

    Explain the workflow of the thesis and future sections

% where you frame what you will present in future chapters. 
% It explains the context in which your work has taken
% place. This might make reference to a particular field or perhaps a problem that your
% work addresses. The introduction contains your thesis statement and your contributions.
% It also describes how the rest of your thesis will be organized. It normally, is not very
% long, should be compelling and typically forms chapter one of your thesis.


The ‘literature review’ is the part of the thesis where there is
extensive reference to related research and theory in your field; it is
where connections are made between the source texts that you draw
on and you position your research among these sources.
\\

The ‘literature review’ is where you identify the theories and
previous research which have includes in your choice of research
topic ... you can use the literature to support your
identification of a problem to research and to illustrate that there is
a gap in previous research which needs to be filled.
\\

Describes the knowledge about the studied matter through the
analysis of similar or related published work.
\\Provides a comprehensive overview of what was done, what has
been done in the field and what should be further investigated.
\\


\section{Metodología e implementación}
This is the section of your thesis where you will present the methodological framework
for your research. It discusses how you would do what you have already done, if you
were to start again. Methodology chapters are intended to be complete, detailed reports of
what someone would need to do to replicate your results with the objective that any other
researcher could repeat your work exactly to determine if your results can be replicated.
\\

This section will also describe any experiments you may have run, it will also discuss any testing methodologies and how these would be actually applied in your case. In essence, this is the section where you disclose how you measure your results to the world but do not actually give the results.
\\
Do not include implementation details.\\
Do not include how you arrived at your solution.\\
Do not mix evaluation and approach.(You will evaluate your approach, but that should be in a different section.)\\
Do include a picture.\\


\section{Resultados}
In this section you will report the results of your work with reference to the methodology
you discussed in the previous section. It is very important that you report the results of
your evaluation in relation to your thesis statement. This will bolster your arguments
concerning the validity of your statement and will make it more difficult to attack. In
many cases the claims you made in the first section of your thesis can now be
substantiated as well.
\\

Generally speaking, it is a good idea to break this part of your thesis into section that
addresses a single claim at a time by applying your methodology, reporting a result and
discussing the result in the context of your thesis statement.
This section will normally form chapter four and is essentially the “meat” of your
document and may take more than one chapter to present
\\

After you have presented your approach, it is time to show why it is so great with an evaluation.


\section{Conclusions, Summary and Future Work}
critically evaluates your approach and evaluation. Most things we
do in computer science are not perfect: There will be edge cases, limitations, or scenarios where other approaches are better. This section is your opportunity to acknowledge the weaknesses of your thesis and discuss why or why not they matter (and how they could be addressed by someone else extending your approach).\\

This thesis has presented a novel approach to music information retrieval with natural language queries, that leverages the power of music information 
retrieval classifiers and sentence embeddings. 

Through our exploration, we have shown the potential of using machine learning classifiers to extract nuanced features from music, 
in an attempt to translate its auditory qualities into a natural language description. This step represents a critical bridge between the abstract 
nature of music and the linguistic realm of human communication, reducing the semantic gap and paving the way for enhanced music retrieval systems. 
There lays the importance of continuing this path of investigation and find better ways to perform the transformation from music characteristics 
to neat human perception texts. Most likely the way to improve on this endeavor is following the great advancements in language models of the last 
couple of years (whether it is TableGPT or other approach). 

Our results underscore the potential for practical applications within the music industry, suggesting that this approach could revolutionize the 
way users interact with and discover music. From personalized recommendations to more intuitive search interfaces, the impact of this research 
extends beyond the realm of academia, resonating profoundly within the domain of music technology.

However, it's important to acknowledge the constraints of our work. While our framework shows promise, there are still challenges to be addressed, 
such as the interpretability of the natural language descriptions and the scalability of the retrieval process. It is also important to address the 
fact that there's still no datasets for the text-to-music retrieval task, and the adyacents ones aren't of suitable size. We recognize that the causes 
of the unavailability of datasets must also be addressed. Among them can be found: the aformentioned copyright problem, the fact that alignment of 
text and audio is a hard computational task and should be controlled by human supervision, and that there is no largely adopted standard for 
multimodal music representation. Recent multimodal representation learning approaches have shown breakthough in many domains by taking advantage 
of enormous data from the web, but not on music domains (at leats not in public researches).


The potential for further advancements in music retrieval, recommendation systems, and data-driven musicology is vast, and our work lays the 
foundation for these future endeavors. This is a first attempt at building a free-form natural language interface for music
audio and there is plenty of room for improvement.

% Through an extensive set of experiments, we validated the main design choices in our core approach. \cite{Manco2022ContrastiveAL}
% However, our current dataset is limited to music tags, such as genre, mood, and instrument. A more generalizable music retrieval system needs 
% to cover other musical attributes, such as the tempo, key, chord progression, melody, artist, etc.