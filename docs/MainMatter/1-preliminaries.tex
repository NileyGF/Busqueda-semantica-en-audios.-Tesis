%===================================================================================
% Chapter: Development
%===================================================================================
\chapter{Desarrollo}
\label{chap:development} 
%===================================================================================

\section{Marco teórico}
\label{sec:sota}  
Este trabajo se relaciona con varios temas en la literatura: procesamiento y recuperación de información musical, recuperación de música basada en texto, brecha semántica, procesamiento de lenguaje natural en Recuperación de Información Musical(MIR, por sus siglas en inglés), descripción de música (\textit{Music captioning}), aprendizaje a partir de supervisión de lenguaje y \textit{embeddings} en recuperación de información.\\

\subsection{Procesamiento y recuperación de información musical}
\label{subsec:MIR}
El campo de investigación de MIR se ocupa de la extracción e inferencia de características significativas de la música (ya sea desde las señales de audio, representación simbólica o fuentes externas como páginas web), indexando la música usando estas características y desarrollando diferentes esquemas de búsqueda y recuperación (por ejemplo, búsqueda basada en contenido, sistemas de recomendación musical o interfaces de usuario para explorar grandes colecciones de música) \cite{Schedl2014MusicIR}.

La música es un artefacto humano altamente multimodal. En este caso, por modalidad nos referimos a una forma específica de digitalizar la información musical \cite{Simonetta2019MultimodalMI}. Diferentes modalidades se obtienen a través de diferentes transductores, en diferentes lugares o momentos, y/o pertenecen a diferentes medios. Ejemplos de modalidades que pueden asociarse a una sola pieza de música incluyen audio, letras, partituras simbólicas, portadas de álbumes, y así sucesivamente \cite{Simonetta2019MultimodalMI, Schedl2014MusicIR}.

Los enfoques computacionales en MIR típicamente emplean características y crean modelos para describir la música por una o más de las siguientes categorías de percepción musical: contenido musical, contexto musical, propiedades del usuario y contexto del usuario, como se define en \cite{Schedl2014MusicIR}. Se hace referencia al contenido musical como los aspectos codificados en la señal de audio, tales como: ritmo, melodía, volumen, letras de canciones y timbre. Mientras que el contexto musical se define como factores que no pueden extraerse directamente del audio, pero que están relacionados, no obstante, con el ítem musical, el artista o el intérprete. Al centrarse en el usuario, los aspectos del contexto del usuario representan factores dinámicos y frecuentemente cambiantes, y las propiedades del usuario se refieren a características constantes o de cambio lento, como sus gustos musicales o educación musical.

Es importante señalar que existen interconexiones entre algunas características de diferentes categorías. Por ejemplo, los aspectos reflejados en el contexto musical (por ejemplo, el género musical) pueden ser modelados por el contenido musical (por ejemplo, la instrumentación).

\textbf{Aplicaciones de procesamiento y recuperación de información musical}
\begin{itemize}
    \item La recuperación de música tiene la intención de ayudar a los usuarios a encontrar música en grandes colecciones según un criterio particular de similitud. En query-by humming (búsqueda por tarareo) y query-by example (búsqueda mediante ejemplo), el objetivo es recuperar música a partir de una entrada melódica o rítmica dada. Se basan en la comparación de una señal musical objetivo con una base de datos, pero los usuarios pueden querer encontrar música que cumpla con ciertos requisitos (por ejemplo, "dame canciones con un tempo de 100 bpm o en do mayor") \cite{Schedl2014MusicIR}. De hecho, las personas generalmente usan etiquetas o descripciones semánticos (por ejemplo, "alegre" o "rock") para referirse a la música. Los sistemas de recuperación basados en etiquetas semánticas o categorías...
    \item El alineamiento o sincronización de audio es un escenario similar a la recuperación de música donde, además de identificar un fragmento de audio dado, el objetivo es conectar localmente, posiciones temporales de dos señales musicales.
    \item Los sistemas de recomendación de música suelen proponer una lista de piezas musicales basándose en modelar las preferencias musicales del usuario.
    \item La generación automática de listas de reproducción está relacionada con la recomendación de música. Su objetivo es crear una lista ordenada de resultados, como pistas musicales o artistas, para proporcionar listas de reproducción significativas y agradables para el oyente. Una de las diferencias entre la recomendación de música y la generación de listas de reproducción es que la primera suele proponer nuevas canciones no conocidas por el usuario, mientras que la segunda tiene como objetivo reorganizar material ya conocido.
\end{itemize}
\textbf{Tareas de procesamiento y recuperación de información musical}
\begin{itemize}
    \item Extracción de características (features) del contenido y contexto musical. Las características de audio pueden subdividirse en físicas y perceptuales \cite{Alas2016ARO}. Las físicas, que pueden calcularse en diversos dominios como el tiempo, la frecuencia o la wavelet, incluyen zero-crossing rate, la amplitud, el ritmo, basadas en autoregresión, basadas en STFT (Transformada de Fourier de Tiempo Corto), brillo, tonalidad, croma y forma del espectro. Por otro lado, las características perceptuales intentan integrar el procesamiento de percepción del sonido humano. Por ejemplo, los Coeficientes Cepstrales de Frecuencia Mel (MFCC), paquetes de wavelets perceptuales, y la intensidad sonora.\\
    \item La similitud es la tarea de calcular la la semejanza entre el contenido de la información. A menudo, esta tarea tiene el propósito de recuperar documentos de una colección a través de una consulta, que puede ser explícitamente expresada por el usuario o deducida implícitamente por el sistema \cite{Simonetta2019MultimodalMI}. Un ejemplo muy común de consultas de similitud explícita es la búsqueda por ejemplo, en la cual la consulta está representada por una grabación de audio y el sistema recupera la canción correcta. Por otro lado, las consultas implícitas se utilizan en sistemas de recomendación y generadores de listas de reproducción.
    \item La clasificación consiste en tomar como entrada una pieza musical y devolver una o más etiquetas. Una tarea de clasificación popular es el reconocimiento del estado de ánimo o la emoción \cite{Kim2010StateOT}, mientras que una emergente es la clasificación de género \cite{Allamy20211DCA, AthulyaK2021DeepLB, Qiu2021DBTMPEDB, Rafi2021ComparativeAO, Koparde2021ASO, Ndou2021MusicGC, Prince2022MusicGC}. Ambas tareas pueden aprovechar grabaciones de audio, letras, portadas y metadatos. Otras tareas de clasificación incluyen: clasificación de instrumentos, clasificación de obras derivadas, identificación de tonos y descripción musical expresiva.
\end{itemize}
\subsection{Recuperación de música basada en texto}
\label{subsec:text-based retrieval}
Con el paso de los años, se han propuesto numerosos enfoques para navegar, buscar y descubrir música a través de una variedad de interfaces \cite{Manco2022ContrastiveAL}. Más allá de la búsqueda simple por metadatos, los sistemas de recuperación de música permiten expresar consultas a través de letras \cite{Tsukuda2017LyricJA}, ejemplos de audio \cite{Lee2020DisentangledMM}, videos \cite{Li2019QueryBV} y tarareos \cite{Patel2021MusicRS}, entre otros.

A pesar de que cada uno de estos tipos de consulta tiene sus méritos, ninguno de ellos admite una de las formas más populares de buscar música en la actualidad: mediante texto libre. Por ejemplo, comúnmente buscamos canciones escribiendo texto en un motor de búsqueda o preguntando a comunidades en línea para identificar una pieza de música de la que no tenemos información bibliográfica o editorial. Habilitar a los sistemas MIR para interpretar consultas en lenguaje natural puede tener beneficios de gran alcance \cite{Manco2022ContrastiveAL}.

Un sistema de recuperación basado en texto ideal necesita ser flexible para permitir varios tipos de entrada (como palabras, oraciones) y tener vocabularios abundantes. Por ejemplo, se pueden utilizar etiquetas populares como el género, para explorar la biblioteca musical. A veces, las consultas de entrada pueden incluir tipos de etiquetas musicales no vistas anteriormente. Además, uno puede utilizar descripciones más detalladas a nivel de oración para descubrir música. % TODO rephrase

La recuperación basada en texto es desafiante porque necesita manejar, no solo metadatos editoriales (título, artista, año de lanzamiento), sino también información semántica (género, estado de ánimo, tema). Además, los sistemas modernos de recuperación, como los asistentes de voz, necesitan generalizar a entradas de lenguaje natural a nivel de oración; más allá de vocabularios con etiquetas fijas \cite{Doh2022TowardUT}.

Otro enfoque reciente para la recuperación de información (IR) es a través de modelos neuronales de ranking, que utilizan redes neuronales superficiales o profundas. Los modelos tradicionales de aprendizaje de clasificación emplean técnicas de aprendizaje automático sobre \textit{features} hechos a mano. En contraste, los modelos neuronales aprenden representaciones del lenguaje a partir de texto puro; que pueden disminuir la brecha entre el vocabulario de la consulta y el del documento \cite{Mitra2017NeuralMF}.

Desde el comienzo de la década, ha habido mejoras dramáticas en el rendimiento en tareas de visión por computadora, reconocimiento de voz y traducción automática, tanto en la investigación como en aplicaciones del mundo real \cite{LeCun2015DeepL}. Estos avances han sido propulsados en gran medida por los recientes progresos en modelos de redes neuronales, generalmente con múltiples capas ocultas, conocidos como arquitecturas profundas (\textit{deep learning}) \cite{LeCun2015DeepL, Bahdanau2014NeuralMT, Deng2014DeepLM, Hinton2012DeepNN}. 

Los modelos neuronales para IR utilizan representaciones vectoriales de texto y suelen contener una gran cantidad de parámetros que necesitan ser ajustados. Los modelos de aprendizaje automático (machine learning, ML) con un gran conjunto de parámetros suelen requerir una gran cantidad de datos de entrenamiento \cite{Taylor2006OptimisationMF}.

El aprendizaje de representaciones adecuadas de texto, también requiere \textit{datasets} a gran escala durante el entrenamiento \cite{Mitra2016LearningTM}. Por lo tanto, a diferencia de los modelos clásicos de IR, estos enfoques neuronales tienden a requerir muchos datos; mejorando su rendimiento con la cantidad de datos de entrenamiento \cite{Mitra2017NeuralMF}.

Los enfoques más similares a nuestra investigación son los estudios en \cite{Manco2022ContrastiveAL, Huang2022MuLanAJ}, que utilizan aprendizaje contrastivo cruzado y multimodal para crear un espacio compartido de \textit{embeddings} o \textit{embeddings} multimodales. En noviembre de 2022, \cite{Doh2022TowardUT} ahonda en un estudio de diseños efectivos para sistemas de recuperación de texto-música, proponiendo un sistema universal de recuperación de texto-música, que logra un rendimiento de recuperación comparable tanto en consultas a nivel de \textit{tags} como a nivel de oraciones.
\subsection{Brecha semántica (Semantic gap)}
\label{subsec:semantic-gap}
La brecha semántica en la recuperación de música se refiere a la diferencia entre descripciones acústicas de bajo nivel y conceptos humanos de alto nivel (significativos para la percepción musical humana). Por ejemplo, el mismo tempo puede aparecer en diferentes géneros musicales, y un género musical dado puede estar caracterizado por diferentes tempos \cite{Su2022HighperformanceCM}.

Esta brecha existe porque las características que los ordenadores pueden analizar, como el tono, el tempo y el volumen, no son los mismos que los conceptos que los humanos utilizan para relacionarse con colecciones de música \cite{Celma2006BridgingTM}. Idealmente, los enfoques de recuperación y recomendación de música deberían incorporar aspectos de varias categorías para superar la brecha semántica \cite{Schedl2014MusicIR}.

Un enfoque multimodal para superar la brecha semántica en la música implica combinar diversas técnicas y fuentes de datos para mejorar la precisión de los sistemas de recuperación y recomendación de música \cite{Celma2006AMA}.
\subsection{Procesamiento de Lenguaje Natural en MIR}
\label{subsec:NLP_in_MIR}
El Procesamiento de Lenguaje Natural (NLP, por sus siglas en inglés) es un campo de la Ciencia de la Computación y la Inteligencia Artificial, que se ocupa de la interacción entre las computadoras y el lenguaje humano (natural) \cite{NLP4MIR}. El NLP es un componente fundamental en tecnologías de la vida diaria: búsqueda en la web, reconocimiento y síntesis de voz, resúmenes automáticos en la web, recomendación de productos (incluida la música), traducción automática, entre otros.

Trabajos previos en la literatura de MIR han explorado aprovechar NLP en el ámbito musical desde diferentes enfoques. Los esfuerzos iniciales se centraron en el texto como una modalidad aislada, adoptando técnicas para construir bases de conocimiento a partir de corpus de texto relacionados con la música \cite{Oramas2016InformationEF}, o construir grafos semánticos para la similitud entre artistas a partir de biografías \cite{Oramas2015ASA}. Los esfuerzos recientes han comenzado a favorecer, en cambio, enfoques multimodales. Estos han explorado el aprendizaje profundo con datos de entrada multimodales, típicamente audio combinado con texto, como reseñas o letras, para aplicaciones tan variadas como la clasificación y recomendación musical \cite{Oramas2018MultimodalDL}, detección de estado de ánimo \cite{Delbouys2018MusicMD}, reconocimiento de emociones en la música \cite{Jeon2017MusicER} y descripción de música (captioning) \cite{Manco2021MusCapsGC, Cai2020MusicAA}.

Por otro lado, la idea de permitir que los sistemas de MIR interpreten consultas en lenguaje natural no es nueva; algunos trabajos como \cite{Whitman2002MusicalQA} han sugerido direcciones de investigación similares. Sin embargo, hasta recientemente, los sistemas multimodales que integran lenguaje natural no han sido ampliamente adoptados dentro de la comunidad de MIR, posiblemente debido a la falta de \textit{datasets} adecuados o a las limitaciones prácticas de los métodos de NLP anteriores a los modelos de lenguaje modernos \cite{Manco2022ContrastiveAL}. A la luz de los avances recientes en modelos de lenguaje, se argumenta que el aprendizaje audio-lenguaje tiene el potencial de cerrar la brecha semántica en MIR.

\subsection{Descripción de música (\textit{Music captioning})}
\label{subsec:music_captioning}
\textit{Music captioning} se define como la tarea de generar una descripción en lenguaje natural del contenido de audio de la música de una manera humana.
MusCaps \cite{Manco2021MusCapsGC} en 2021, afirman presentar el primer modelo de \textit{music audio captioning}. Hasta hace poco, los enfoques en MIR para la descripción de música normalmente se basaban en clasificación de una o múltiples etiquetas (\textit{label}). Un ejemplo destacado es el \textit{auto-tagging} de música \cite{Choi2016AutomaticTU, Lee2017SamplelevelDC, Pons2017EndtoendLF}, en el cual se asignan \textit{tags} descriptivos a un fragmento musical para transmitir características de alto nivel de la entrada, como género, instrumentación y emoción.

Los sistemas de \textit{captioning} necesitan reconocer características a nivel de señal como la instrumentación y descriptores de alto nivel como el género. También producen oraciones descriptivas completamente formadas que se asemejan más a las consultas humanas. A través del uso conjunto y procesamiento de información auditiva y lingüística, \textit{music captioning} representa un primer paso hacia el desarrollo de modelos de audio y lenguaje para la comprensión musical. Finalmente, la descripción de música tiene varias aplicaciones directas, como habilitar la búsqueda de música a través de consultas más naturalmente humanas, o proporcionar explicaciones para recomendaciones automáticas de música \cite{Manco2021MusCapsGC}.

El estudio \textit{Audio Retrieval with Natural Language Queries: A Benchmark Study} \cite{Koepke2021AudioRW} se centra en la recuperación de eventos de audio (no musicales) mediante consultas en lenguaje natural. Considerando que aprender (en el sentido de  \textit{machine learning} ) a recuperar audio con consultas en lenguaje natural requiere datos con texto y sonido emparejados, \cite{Koepke2021AudioRW} afirma que los \textit{datasets} de \textit{audio captioning} se prestan naturalmente a esta tarea, ya que contienen audio y una descripción de texto correspondiente al sonido. Proponen aprender \textit{cross-modal embeddings} utilizando \textit{datasets} de \textit{audio captioning} para el sistema de recuperación. Varios estudios en recuperación de música con consultas en lenguaje natural mencionan esta idea con \textit{datasets} de \textit{music captioning} \cite{Doh2022TowardUT, Manco2022ContrastiveAL, Huang2022MuLanAJ}. Sin embargo, también se señala que los \textit{datasets} existentes actualmente no abarcan la diversidad del lenguaje descriptivo del sonido \cite{Huang2022MuLanAJ}; mientras que \cite{Doh2022TowardUT} termina utilizando una concatenación de \textit{tags} de diferentes fuentes de anotación como \textit{captions}.
\subsection{Aprendizaje a partir de Supervisión de Lenguaje}
\label{subsec:learning_lang_superv}
El aprendizaje multimodal todavía ocupa un papel marginal en MIR y aún no ha disfrutado completamente de los beneficios de los modelos de lenguaje modernos \cite{Manco2022ContrastiveAL}. La idea clave detrás de estos modelos es que el lenguaje captura muchas de las abstracciones que los humanos utilizan para navegar por el mundo y, por lo tanto, puede actuar como supervisión para el aprendizaje de propósito general, incluso en tareas que no se basan directamente en el lenguaje.

Los clasificadores generalmente se entrenan para etiquetar ejemplos, con clases predefinidas y fijas. Impulsados por los avances recientes en modelación neuronal de lenguaje y su competencia demostrada en aprendizaje por transferencia, los investigadores han comenzado a explorar menos restrictivas interfaces de lenguaje natural, para acceder a la información categórica subyacente a las señales sin procesar \cite{Huang2022MuLanAJ}. La mayoría de este trabajo se ha centrado en el dominio de eventos visuales y de audio, combinando contenido multimedia con subtítulos en lenguaje natural \cite{Koepke2021AudioRW, Jia2021ScalingUV, Radford2021LearningTV, Nagrani2022LearningAM}.

El éxito de estos esfuerzos depende en gran medida de recursos de entrenamiento a gran escala y de arquitecturas de redes neuronales robustas, que sean lo suficientemente flexibles para modelar la compleja y no monótona relación entre el lenguaje y otras modalidades. En particular, el dominio visual ha obtenido grandes beneficios de la disponibilidad de grandes cantidades de imágenes con descripciones disponibles en la web \cite{Jia2021ScalingUV}. Sin embargo, en el dominio general de audio ambiental, pares de audio-descripción a gran escala están menos disponibles y los esfuerzos relacionados se han basado pequeños \textit{datasets} de \textit{captions} \cite{Drossos2019ClothoAA, Kim2019AudioCapsGC}.
\subsection{\textit{Embeddings} en recuperación de información}
\label{subsec:semantic_embedd}
Un \textit{embedding} es una representación de elementos en un nuevo espacio, de manera que se preservan las propiedades y relaciones entre los elementos. El objetivo de un \textit{embedding} es generar una representación más simple, donde la simplificación puede implicar una reducción en el número de dimensiones, un aumento en la dispersión de la representación, desentrañar los componentes principales del espacio vectorial, o una combinación de estos objetivos \cite{Mitra2017NeuralMF}.

Los \textit{embeddings} de palabras, de modelos pre-entrenados, se utilizan en diversas aplicaciones, como en la construcción de representaciones para frases, párrafos y documentos \cite{Brundha2022VectorMB}. Con modelos de \textit{embedding} de palabras, los documentos preprocesados se mapean a vectores de números reales mediante tecnologías como redes neuronales, reducción de dimensionalidad en la matriz de co-ocurrencia de palabras, entre otras \cite{Yuan2020ImprovingIR}.\\
Dado que tienen en cuenta el contexto donde aparecen las palabras, permite la predicción de palabras faltantes en un documento. En contraste, los motores de búsqueda tradicionales, basados en palabras clave, no pueden resolver el problema de la alta discrepancia entre términos; y considerar las diferencias de significado entre palabras semánticamente similares en el proceso de comparación. 

Los modelos de \textit{embeddings} más utilizados/estudiados en la literatura incluyen:
\begin{itemize}
    \item \textbf{Word2vec} \cite{Mikolov2013EfficientEO} (2013): es un conjunto de modelos relacionados que se utilizan para producir \textit{embeddings} de palabras. Estos modelos son redes neuronales superficiales de dos capas que se entrenan para reconstruir contextos lingüísticos de palabras. Word2vec puede utilizar dos arquitecturas de modelo para producir estas representaciones distribuidas de palabras: \textit{Continuous Bag-Of-Words} (CBOW) o \textit{skip-gram} de deslizamiento continuo. En ambas arquitecturas, word2vec considera tanto palabras individuales como una ventana de contexto deslizante a medida que itera sobre el corpus. El problema de la dispersión en word2vec causa que la dimensión de su espacio vectorial sea mayor que otras tecnologías, lo que provoca un uso excesivo de recursos de memoria y una baja robustez \cite{Yuan2020ImprovingIR}.
    \item \textbf{GloVe} \cite{Pennington2014GloVeGV} (2014): acuñado a partir de su nombre en inglés \textit{Global Vectors}, es un algoritmo de aprendizaje no supervisado para obtener representaciones vectoriales de palabras. Resulta en un modelo global de regresión log-bilineal que combina las ventajas de las dos principales familias de modelos en la literatura: factorización de matrices globales y métodos locales de ventana de contexto.
    \item \textbf{BERT} \cite{Devlin2019BERTPO} (2019): abreviatura de \textit{Bidirectional Encoder Representations from Transformers}, es un modelo de lenguaje basado en la arquitectura \textit{transformer}, notable por su mejora dramática respecto a anteriores modelos en el estado del arte. El modelo pre-entrenado de BERT puede ser ajustado (\textit{fine-tuning}) con solo una capa de salida adicional, para crear modelos de última generación para una amplia gama de tareas; como respuesta a preguntas e inferencia de lenguaje, sin modificaciones sustanciales en la arquitectura específica de la tarea. \textit{Sentence BERT} (SBERT) \cite{Reimers2019SentenceBERTSE} es un algoritmo basado en aprendizaje automático que utiliza un \textit{transformer} de oraciones para generar \textit{embeddings} de oraciones mediante una red neuronal siamesa. SBERT puede ser beneficioso para la búsqueda semántica y la similitud textual semántica.
\end{itemize}

Los sistemas de recuperación de información basados en \textit{embeddings} reciben una entrada del usuario en forma de consulta. Luego, el sistema procesa todas las consultas y genera \textit{embeddings} vectoriales que ayudan a comparar la consulta con la colección de documentos del corpus. Los \textit{embeddings} de la consulta y del documento pueden compararse utilizando una variedad de métricas de similitud, como la similitud del coseno o el producto punto. Los documentos relevantes se envían al usuario en orden decreciente de relevancia, lo que ayuda a identificar cuáles resultados son mejores.
